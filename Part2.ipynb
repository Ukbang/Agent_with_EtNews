{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_community.document_loaders.csv_loader import CSVLoader\n",
    "import pandas as pd\n",
    "from IPython.display import Markdown\n",
    "\n",
    "from typing import Annotated, Literal\n",
    "from typing_extensions import TypedDict\n",
    "from langchain_openai import ChatOpenAI, OpenAIEmbeddings\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain_community.vectorstores import FAISS\n",
    "from langchain_community.tools.tavily_search import TavilySearchResults\n",
    "from langchain.tools.retriever import create_retriever_tool\n",
    "from langchain.document_loaders import PyMuPDFLoader, PyPDFLoader\n",
    "from langgraph.graph import StateGraph, START, END\n",
    "from langgraph.graph.message import add_messages\n",
    "from langgraph.prebuilt import ToolNode, tools_condition\n",
    "from langgraph.checkpoint.memory import MemorySaver\n",
    "from langchain_core.prompts import ChatPromptTemplate, PromptTemplate\n",
    "from langchain_core.documents.base import Document\n",
    "from langchain_core.vectorstores.base import VectorStoreRetriever\n",
    "from langchain_core.output_parsers.openai_tools import JsonOutputToolsParser\n",
    "from langchain_core.output_parsers.string import StrOutputParser\n",
    "from langchain.schema.runnable import RunnablePassthrough, RunnableLambda\n",
    "from langchain_experimental.utilities import PythonREPL\n",
    "from pydantic import BaseModel, Field\n",
    "from markitdown import MarkItDown\n",
    "import dotenv\n",
    "import os\n",
    "\n",
    "dotenv.load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"./data/titanic.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Survived</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Name</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Ticket</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Cabin</th>\n",
       "      <th>Embarked</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Braund, Mr. Owen Harris</td>\n",
       "      <td>male</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>A/5 21171</td>\n",
       "      <td>7.2500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Cumings, Mrs. John Bradley (Florence Briggs Th...</td>\n",
       "      <td>female</td>\n",
       "      <td>38.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>PC 17599</td>\n",
       "      <td>71.2833</td>\n",
       "      <td>C85</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>Heikkinen, Miss. Laina</td>\n",
       "      <td>female</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>STON/O2. 3101282</td>\n",
       "      <td>7.9250</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Futrelle, Mrs. Jacques Heath (Lily May Peel)</td>\n",
       "      <td>female</td>\n",
       "      <td>35.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>113803</td>\n",
       "      <td>53.1000</td>\n",
       "      <td>C123</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Allen, Mr. William Henry</td>\n",
       "      <td>male</td>\n",
       "      <td>35.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>373450</td>\n",
       "      <td>8.0500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   PassengerId  Survived  Pclass  \\\n",
       "0            1         0       3   \n",
       "1            2         1       1   \n",
       "2            3         1       3   \n",
       "3            4         1       1   \n",
       "4            5         0       3   \n",
       "\n",
       "                                                Name     Sex   Age  SibSp  \\\n",
       "0                            Braund, Mr. Owen Harris    male  22.0      1   \n",
       "1  Cumings, Mrs. John Bradley (Florence Briggs Th...  female  38.0      1   \n",
       "2                             Heikkinen, Miss. Laina  female  26.0      0   \n",
       "3       Futrelle, Mrs. Jacques Heath (Lily May Peel)  female  35.0      1   \n",
       "4                           Allen, Mr. William Henry    male  35.0      0   \n",
       "\n",
       "   Parch            Ticket     Fare Cabin Embarked  \n",
       "0      0         A/5 21171   7.2500   NaN        S  \n",
       "1      0          PC 17599  71.2833   C85        C  \n",
       "2      0  STON/O2. 3101282   7.9250   NaN        S  \n",
       "3      0            113803  53.1000  C123        S  \n",
       "4      0            373450   8.0500   NaN        S  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 891 entries, 0 to 890\n",
      "Data columns (total 12 columns):\n",
      " #   Column       Non-Null Count  Dtype  \n",
      "---  ------       --------------  -----  \n",
      " 0   PassengerId  891 non-null    int64  \n",
      " 1   Survived     891 non-null    int64  \n",
      " 2   Pclass       891 non-null    int64  \n",
      " 3   Name         891 non-null    object \n",
      " 4   Sex          891 non-null    object \n",
      " 5   Age          714 non-null    float64\n",
      " 6   SibSp        891 non-null    int64  \n",
      " 7   Parch        891 non-null    int64  \n",
      " 8   Ticket       891 non-null    object \n",
      " 9   Fare         891 non-null    float64\n",
      " 10  Cabin        204 non-null    object \n",
      " 11  Embarked     889 non-null    object \n",
      "dtypes: float64(2), int64(5), object(5)\n",
      "memory usage: 83.7+ KB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "md = MarkItDown()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "convert_df = md.convert(\"./data/titanic.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "convert_df = convert_df.text_content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = PromptTemplate.from_template(\n",
    "    \"\"\"\n",
    "    table : {convert}\n",
    "\n",
    "    당신은 데이터 분석 전문가입니다.\n",
    "    주어진 table 데이터를 기반으로 데이터 분석에 도움을 주세요.\n",
    "\n",
    "    query : {query}\n",
    "\n",
    "    \"\"\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "llm = ChatOpenAI(model=\"gpt-4o-mini\",\n",
    "                 temperature=0.,)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "chain = prompt | llm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "query = \"이 데이터의 총 행의 갯수는 몇 개인가요?\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = chain.invoke({\"convert\":convert_df,\n",
    "                       \"query\" : query\n",
    "                       })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'주어진 데이터의 총 행의 갯수는 891개입니다.'"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def chat_llm(query):\n",
    "    result = chain.invoke({\"convert\":convert_df,\n",
    "                       \"query\" : query\n",
    "                       })    \n",
    "    \n",
    "    return result.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = chat_llm(\"이 데이터에서 얻을 수 있는 인사이트는 무엇인가요?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "주어진 데이터는 타이타닉 승객에 대한 정보로, 여러 가지 인사이트를 도출할 수 있습니다. 다음은 이 데이터를 기반으로 얻을 수 있는 몇 가지 인사이트입니다:\n",
      "\n",
      "1. **생존율 분석**:\n",
      "   - 전체 승객 중 생존한 비율과 사망한 비율을 계산하여 생존율을 분석할 수 있습니다.\n",
      "   - 성별, 나이, 선실 등급(Pclass)별로 생존율을 비교하여 어떤 그룹이 더 높은 생존율을 보였는지 확인할 수 있습니다.\n",
      "\n",
      "2. **성별에 따른 생존율**:\n",
      "   - 남성과 여성의 생존율을 비교하여 성별이 생존에 미친 영향을 분석할 수 있습니다. 일반적으로 여성의 생존율이 남성보다 높았던 것으로 알려져 있습니다.\n",
      "\n",
      "3. **연령대별 생존율**:\n",
      "   - 연령대별로 생존율을 분석하여 어린이, 청소년, 성인, 노인 등 각 연령대의 생존율을 비교할 수 있습니다. 예를 들어, 어린이의 생존율이 높았는지 확인할 수 있습니다.\n",
      "\n",
      "4. **선실 등급(Pclass) 분석**:\n",
      "   - 선실 등급별로 생존율을 분석하여 고급 선실(Pclass 1) 승객이 더 높은 생존율을 보였는지 확인할 수 있습니다. 이는 사회적 지위가 생존에 미친 영향을 나타낼 수 있습니다.\n",
      "\n",
      "5. **가족 구성원 수에 따른 생존율**:\n",
      "   - Sibling(형제/자매) 및 Parch(부모/자녀) 수에 따라 생존율을 분석하여 가족과 함께 탑승한 승객이 생존에 유리했는지 확인할 수 있습니다.\n",
      "\n",
      "6. **요금(Fare) 분석**:\n",
      "   - 요금 지불 금액에 따른 생존율을 분석하여 높은 요금을 지불한 승객이 생존할 확률이 더 높았는지 확인할 수 있습니다.\n",
      "\n",
      "7. **탑승 항구(Embarked) 분석**:\n",
      "   - 탑승 항구별로 생존율을 분석하여 어떤 항구에서 탑승한 승객이 더 높은 생존율을 보였는지 확인할 수 있습니다.\n",
      "\n",
      "8. **결혼 여부 및 가족 관계**:\n",
      "   - 승객의 이름에서 결혼 여부를 추정하여 결혼한 여성과 미혼 여성의 생존율을 비교할 수 있습니다.\n",
      "\n",
      "9. **결측치 분석**:\n",
      "   - 나이(Age)와 같은 중요한 변수에서 결측치가 존재하므로, 이를 처리하는 방법(예: 평균, 중앙값 대체 등)을 분석하여 데이터의 품질을 향상시킬 수 있습니다.\n",
      "\n",
      "10. **시각화**:\n",
      "    - 생존율, 성별, 연령대, 선실 등급 등의 관계를 시각화하여 데이터의 패턴을 쉽게 이해할 수 있도록 도와줄 수 있습니다. 예를 들어, 막대 그래프, 히스토그램, 산점도 등을 활용할 수 있습니다.\n",
      "\n",
      "이러한 인사이트를 통해 타이타닉 사건에 대한 이해를 높이고, 생존에 영향을 미친 요인들을 분석할 수 있습니다.\n"
     ]
    }
   ],
   "source": [
    "print(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfccs = pd.read_csv(\"./data/cookie_cats.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 90189 entries, 0 to 90188\n",
      "Data columns (total 5 columns):\n",
      " #   Column          Non-Null Count  Dtype \n",
      "---  ------          --------------  ----- \n",
      " 0   userid          90189 non-null  int64 \n",
      " 1   version         90189 non-null  object\n",
      " 2   sum_gamerounds  90189 non-null  int64 \n",
      " 3   retention_1     90189 non-null  bool  \n",
      " 4   retention_7     90189 non-null  bool  \n",
      "dtypes: bool(2), int64(2), object(1)\n",
      "memory usage: 2.2+ MB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_experimental.agents.agent_toolkits import create_pandas_dataframe_agent\n",
    "from langchain.agents.agent_types import AgentType\n",
    "import seaborn as sns\n",
    "\n",
    "sns.set_style(\"white\")\n",
    "\n",
    "agent = create_pandas_dataframe_agent(\n",
    "    ChatOpenAI(model=\"gpt-4o-mini\", temperature=0),\n",
    "    dfccs,\n",
    "    verbose=False,\n",
    "    agent_type=AgentType.OPENAI_FUNCTIONS,\n",
    "    allow_dangerous_code=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"verbose=False agent=RunnableAgent(runnable=RunnableAssign(mapper={\\n  agent_scratchpad: RunnableLambda(lambda x: format_to_openai_function_messages(x['intermediate_steps']))\\n})\\n| ChatPromptTemplate(input_variables=['agent_scratchpad', 'input'], input_types={'agent_scratchpad': list[typing.Annotated[typing.Union[typing.Annotated[langchain_core.messages.ai.AIMessage, Tag(tag='ai')], typing.Annotated[langchain_core.messages.human.HumanMessage, Tag(tag='human')], typing.Annotated[langchain_core.messages.chat.ChatMessage, Tag(tag='chat')], typing.Annotated[langchain_core.messages.system.SystemMessage, Tag(tag='system')], typing.Annotated[langchain_core.messages.function.FunctionMessage, Tag(tag='function')], typing.Annotated[langchain_core.messages.tool.ToolMessage, Tag(tag='tool')], typing.Annotated[langchain_core.messages.ai.AIMessageChunk, Tag(tag='AIMessageChunk')], typing.Annotated[langchain_core.messages.human.HumanMessageChunk, Tag(tag='HumanMessageChunk')], typing.Annotated[langchain_core.messages.chat.ChatMessageChunk, Tag(tag='ChatMessageChunk')], typing.Annotated[langchain_core.messages.system.SystemMessageChunk, Tag(tag='SystemMessageChunk')], typing.Annotated[langchain_core.messages.function.FunctionMessageChunk, Tag(tag='FunctionMessageChunk')], typing.Annotated[langchain_core.messages.tool.ToolMessageChunk, Tag(tag='ToolMessageChunk')]], FieldInfo(annotation=NoneType, required=True, discriminator=Discriminator(discriminator=<function _get_type at 0x000001E15D4263B0>, custom_error_type=None, custom_error_message=None, custom_error_context=None))]]}, partial_variables={}, messages=[SystemMessage(content='\\\\nYou are working with a pandas dataframe in Python. The name of the dataframe is `df`.\\\\nThis is the result of `print(df.head())`:\\\\n|    |   userid | version   |   sum_gamerounds | retention_1   | retention_7   |\\\\n|---:|---------:|:----------|-----------------:|:--------------|:--------------|\\\\n|  0 |      116 | gate_30   |                3 | False         | False         |\\\\n|  1 |      337 | gate_30   |               38 | True          | False         |\\\\n|  2 |      377 | gate_40   |              165 | True          | False         |\\\\n|  3 |      483 | gate_40   |                1 | False         | False         |\\\\n|  4 |      488 | gate_40   |              179 | True          | True          |', additional_kwargs={}, response_metadata={}), HumanMessagePromptTemplate(prompt=PromptTemplate(input_variables=['input'], input_types={}, partial_variables={}, template='{input}'), additional_kwargs={}), MessagesPlaceholder(variable_name='agent_scratchpad')])\\n| RunnableBinding(bound=ChatOpenAI(client=<openai.resources.chat.completions.completions.Completions object at 0x000001E1063BD660>, async_client=<openai.resources.chat.completions.completions.AsyncCompletions object at 0x000001E1063D89A0>, root_client=<openai.OpenAI object at 0x000001E1063BEF20>, root_async_client=<openai.AsyncOpenAI object at 0x000001E1063BD690>, model_name='gpt-4o-mini', temperature=0.0, model_kwargs={}, openai_api_key=SecretStr('**********')), kwargs={'functions': [{'name': 'python_repl_ast', 'description': 'A Python shell. Use this to execute python commands. Input should be a valid python command. When using this tool, sometimes output is abbreviated - make sure it does not look abbreviated before using it in your answer.', 'parameters': {'properties': {'query': {'description': 'code snippet to run', 'type': 'string'}}, 'required': ['query'], 'type': 'object'}}]}, config={}, config_factories=[])\\n| OpenAIFunctionsAgentOutputParser(), input_keys_arg=['input'], return_keys_arg=['output'], stream_runnable=True) tools=[PythonAstREPLTool(globals={}, locals={'df':         userid  version  sum_gamerounds  retention_1  retention_7\\n0          116  gate_30               3        False        False\\n1          337  gate_30              38         True        False\\n2          377  gate_40             165         True        False\\n3          483  gate_40               1        False        False\\n4          488  gate_40             179         True         True\\n...        ...      ...             ...          ...          ...\\n90184  9999441  gate_40              97         True        False\\n90185  9999479  gate_40              30        False        False\\n90186  9999710  gate_30              28         True        False\\n90187  9999768  gate_40              51         True        False\\n90188  9999861  gate_40              16        False        False\\n\\n[90189 rows x 5 columns]})]\""
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "str(agent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "streaming = agent.stream({\"input\":query})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'actions': [AgentActionMessageLog(tool='python_repl_ast', tool_input={'query': 'len(df)'}, log=\"\\nInvoking: `python_repl_ast` with `{'query': 'len(df)'}`\\n\\n\\n\", message_log=[AIMessageChunk(content='', additional_kwargs={'function_call': {'arguments': '{\"query\":\"len(df)\"}', 'name': 'python_repl_ast'}}, response_metadata={'finish_reason': 'function_call', 'model_name': 'gpt-4o-mini-2024-07-18', 'system_fingerprint': 'fp_06737a9306'}, id='run-f9ac2467-5137-4137-93f9-61982f58a597')])], 'messages': [AIMessageChunk(content='', additional_kwargs={'function_call': {'arguments': '{\"query\":\"len(df)\"}', 'name': 'python_repl_ast'}}, response_metadata={'finish_reason': 'function_call', 'model_name': 'gpt-4o-mini-2024-07-18', 'system_fingerprint': 'fp_06737a9306'}, id='run-f9ac2467-5137-4137-93f9-61982f58a597')]}\n",
      "{'steps': [AgentStep(action=AgentActionMessageLog(tool='python_repl_ast', tool_input={'query': 'len(df)'}, log=\"\\nInvoking: `python_repl_ast` with `{'query': 'len(df)'}`\\n\\n\\n\", message_log=[AIMessageChunk(content='', additional_kwargs={'function_call': {'arguments': '{\"query\":\"len(df)\"}', 'name': 'python_repl_ast'}}, response_metadata={'finish_reason': 'function_call', 'model_name': 'gpt-4o-mini-2024-07-18', 'system_fingerprint': 'fp_06737a9306'}, id='run-f9ac2467-5137-4137-93f9-61982f58a597')]), observation=90189)], 'messages': [FunctionMessage(content='90189', additional_kwargs={}, response_metadata={}, name='python_repl_ast')]}\n",
      "{'output': '이 데이터프레임의 총 행의 갯수는 90,189개입니다.', 'messages': [AIMessage(content='이 데이터프레임의 총 행의 갯수는 90,189개입니다.', additional_kwargs={}, response_metadata={})]}\n"
     ]
    }
   ],
   "source": [
    "for step in streaming:\n",
    "    print(step)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "이 데이터프레임의 총 행의 갯수는 90,189개입니다.\n"
     ]
    }
   ],
   "source": [
    "print(step[\"output\"])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Modulabs",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
