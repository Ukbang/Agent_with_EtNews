{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from typing import Annotated, Literal\n",
    "from typing_extensions import TypedDict\n",
    "from langchain_openai import ChatOpenAI, OpenAIEmbeddings\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain_community.vectorstores import FAISS\n",
    "from langchain_community.tools.tavily_search import TavilySearchResults\n",
    "from langchain.tools.retriever import create_retriever_tool\n",
    "from langchain.document_loaders import PyMuPDFLoader, PyPDFLoader\n",
    "from langgraph.graph import StateGraph, START, END\n",
    "from langgraph.graph.message import add_messages\n",
    "from langgraph.prebuilt import ToolNode, tools_condition\n",
    "from langgraph.checkpoint.memory import MemorySaver\n",
    "from langchain_core.prompts import ChatPromptTemplate, PromptTemplate\n",
    "from langchain_core.documents.base import Document\n",
    "from langchain_core.vectorstores.base import VectorStoreRetriever\n",
    "from langchain_core.output_parsers.openai_tools import JsonOutputToolsParser\n",
    "from langchain_core.output_parsers.string import StrOutputParser\n",
    "from langchain.schema.runnable import RunnablePassthrough, RunnableLambda\n",
    "from langchain_experimental.utilities import PythonREPL\n",
    "from pydantic import BaseModel, Field\n",
    "import dotenv\n",
    "import os\n",
    "\n",
    "dotenv.load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "llm = ChatOpenAI(model=\"gpt-4o-mini\",\n",
    "                 temperature=0.,)\n",
    "\n",
    "embeddings = OpenAIEmbeddings()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class State(TypedDict):\n",
    "    query : Annotated[str, \"User Question\"]\n",
    "    answer : Annotated[str, \"LLM Response\"]\n",
    "    retriever : Annotated[VectorStoreRetriever, \"VectorStore Retriever\"]\n",
    "    document : Annotated[Document, \"Retrieve Response\"]\n",
    "    prompt : Annotated[ChatPromptTemplate, \"Prompt Template\"]\n",
    "    retrieved : Annotated[bool, \"Retriever Executed\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_initial_state():\n",
    "    return {\"query\":\"\",\n",
    "            \"answer\":\"\",\n",
    "            \"retrieved\":False}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def embedding_file(state:State, file: str):\n",
    "    splitter = RecursiveCharacterTextSplitter.from_tiktoken_encoder(\n",
    "        chunk_size=300,\n",
    "        chunk_overlap=50,\n",
    "        separators=[\"\\n\\n\"],\n",
    "    )\n",
    "\n",
    "    loader = PyPDFLoader(f\"./files/{file}\")\n",
    "    docs = loader.load_and_split(text_splitter=splitter)\n",
    "\n",
    "    embeddings = OpenAIEmbeddings()\n",
    "    vector_store = FAISS.from_documents(docs, embeddings)\n",
    "    retriever = vector_store.as_retriever()    \n",
    "\n",
    "    return {\"retriever\": retriever,\n",
    "            \"retrieved\": True}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def main(state:State):\n",
    "    \n",
    "    query = input()\n",
    "\n",
    "    return {\"query\": query} "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prompt(state:State):\n",
    "    prompt = ChatPromptTemplate.from_messages([\n",
    "        (\"system\", \n",
    "        \"\"\"\n",
    "        context : {context}\n",
    "\n",
    "        당신은 언제나 고객에게 최선을 다해 답변을 하며 말투는 굉장히 친근합니다. 직업은 전문 상담원입니다. 답변 시, 아래의 규칙을 지켜야만 합니다.\n",
    "        ---\n",
    "        ### 규칙 ###\n",
    "        1. 주어진 context만을 이용하여 답변해야합니다. \n",
    "        2. 주어진 context에서 답변을 할 수 없다면 \"해당 문의는 010-2255-3366으로 연락주시면 도와드리겠습니다. 영업 시간은 오전 10시-오후 6시입니다.\" 라고 대답하세요.\n",
    "        3. 문자열에 A1, A2, A11, A22 등 필요 없는 문자는 제거한 뒤 출력합니다.\n",
    "        4. 항상 친절한 말투로 응대합니다.\n",
    "        5. 하이퍼 링크를 그대로 출력합니다. 대소문자를 명확하게 구분하세요. 아래 예시를 참고하여 서식을 맞추세요.\n",
    "        **하이퍼 링크 예시**\n",
    "        5-1. [스타벅스 구역삼사거리점](https://naver.me/FV7K6xTM) 입니다.\n",
    "        5-2. [화목순대국](https://naver.me/FQVGK6TZ) 입니다.\n",
    "        5-3. [모두의연구소 역삼캠퍼스](https://naver.me/GMvc9Hv5) 입니다.\n",
    "        ---\n",
    "        \"\"\"),\n",
    "        (\"human\", \"{query}\")\n",
    "    ])\n",
    "\n",
    "    return {\"prompt\": prompt}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Modulabs",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
